{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternImage Encoder Code Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import logging\n",
    "\n",
    "from .supporting_scripts.checkpoint import _load_checkpoint\n",
    "from .supporting_scripts.dropPath import trunc_normal_, DropPath\n",
    "from .supporting_scripts.logging import get_root_logger\n",
    "from .supporting_scripts.weight_init import constant_init, trunc_normal_init\n",
    "\n",
    "from . import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are part of a PyTorch module designed to convert tensors between two common formats used in deep learning: channels first (NCHW) and channels last (NHWC).\n",
    "\n",
    "The `to_channels_first` class converts a tensor from channels last format (NHWC) to channels first format (NCHW). In the forward method, it takes an input tensor x and rearranges its dimensions using the permute function to swap the channel dimension from the last position (index 3) to the second position (index 1), ensuring the channels are in the correct order for the channels first format.\n",
    "\n",
    "Conversely, the `to_channels_last` class performs the opposite transformation, converting a tensor from channels first format (NCHW) to channels last format (NHWC). In its forward method, it rearranges the dimensions of the input tensor x using permute, moving the channel dimension from the second position (index 1) to the last position (index 3), thereby converting the tensor to channels last format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class to_channels_first(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "class to_channels_last(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `build_norm_layer`, is responsible for constructing a normalization layer based on specified parameters. Let's break it down:\n",
    "\n",
    "The function takes several arguments:\n",
    "\n",
    "* `dim`: The number of channels in the input tensor.\n",
    "* `norm_layer`: The type of normalization layer to be used, which can be either \"BN\" (Batch Normalization) or \"LN\" (Layer Normalization).\n",
    "* `in_format` and `out_format`: The format of the input and output tensors, which can be either \"channels_first\" (NCHW) or \"channels_last\" (NHWC). These parameters determine whether tensor format conversions need to be applied before or after applying the normalization layer.\n",
    "* `eps`: A small value added to the denominator for numerical stability in normalization computations.\n",
    "\n",
    "The function first initializes an empty list called layers to store the components of the normalization layer.\n",
    "\n",
    "Next, it checks the type of normalization layer specified (BN or LN). If norm_layer is set to 'BN', it constructs a sequence of layers for batch normalization. Depending on the input and output tensor formats, it may append instances of `to_channels_first()` or `to_channels_last()` to ensure the tensor is in the correct format before and after applying batch normalization.\n",
    "\n",
    "Similarly, if `norm_layer` is set to 'LN', it constructs a sequence of layers for layer normalization. Again, depending on the input and output tensor formats, it may append instances of `to_channels_first()` or `to_channels_last()` to ensure the tensor is in the correct format before and after applying layer normalization.\n",
    "\n",
    "If the specified `norm_layer` is not supported, the function raises a NotImplementedError.\n",
    "\n",
    "Finally, the function returns a nn.Sequential container containing all the layers constructed based on the specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_norm_layer(dim,\n",
    "                     norm_layer,\n",
    "                     in_format='channels_last',\n",
    "                     out_format='channels_last',\n",
    "                     eps=1e-6):\n",
    "    layers = []\n",
    "    if norm_layer == 'BN':\n",
    "        if in_format == 'channels_last':\n",
    "            layers.append(to_channels_first())\n",
    "        layers.append(nn.BatchNorm2d(dim))\n",
    "        if out_format == 'channels_last':\n",
    "            layers.append(to_channels_last())\n",
    "    elif norm_layer == 'LN':\n",
    "        if in_format == 'channels_first':\n",
    "            layers.append(to_channels_last())\n",
    "        layers.append(nn.LayerNorm(dim, eps=eps))\n",
    "        if out_format == 'channels_first':\n",
    "            layers.append(to_channels_first())\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'build_norm_layer does not support {norm_layer}')\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `build_act_layer`, is responsible for constructing an activation layer based on the specified activation function type. \n",
    "\n",
    "The function takes a single argument:\n",
    "* `act_layer`: The type of activation layer to be used, which can be one of the following: \"ReLU\", \"SiLU\" (Sigmoid Linear Unit), or \"GELU\" (Gaussian Error Linear Unit).\n",
    "\n",
    "The function first checks the type of activation layer specified (`ReLU`, `SiLU`, or `GELU`).\n",
    "\n",
    "If `act_layer` is set to `'ReLU'`, it returns an instance of `nn.ReLU` activation function with `inplace=True`, meaning it modifies the input tensor in-place, which can save memory. If `act_layer` is set to `'SiLU'`, it returns an instance of `nn.SiLU` activation function with `inplace=True`. If `act_layer` is set to `'GELU'`, it returns an instance of `nn.GELU` activation function. If the specified `act_layer` is not supported, the function raises a `NotImplementedError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_act_layer(act_layer):\n",
    "    if act_layer == 'ReLU':\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif act_layer == 'SiLU':\n",
    "        return nn.SiLU(inplace=True)\n",
    "    elif act_layer == 'GELU':\n",
    "        return nn.GELU()\n",
    "\n",
    "    raise NotImplementedError(f'build_act_layer does not support {act_layer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class, `StemLayer`, is used as the initial processing stage the InternImage network, responsible for extracting basic features from the input images. \n",
    "\n",
    "The class constructor `__init__` takes the following arguments:\n",
    "- `in_chans`: The number of input channels to the stem layer. Default is 3, assuming RGB images.\n",
    "- `out_chans`: The number of output channels from the stem layer. Default is 96.\n",
    "- `act_layer`: The type of activation layer to be used within the stem layer. Default is 'GELU' (Gaussian Error Linear Unit).\n",
    "- `norm_layer`: The type of normalization layer to be used within the stem layer. Default is 'BN' (Batch Normalization).\n",
    "\n",
    "Inside the constructor, the stem layer is defined as follows:\n",
    "\n",
    "1. `self.conv1`: A 2D convolutional layer (`nn.Conv2d`) with parameters specified by `in_chans`, `out_chans // 2` (half of the output channels), kernel size 3x3, stride 2, and padding 1. This layer reduces the spatial dimensions of the input tensor while increasing its depth.\n",
    "2. `self.norm1`: The normalization layer applied after the first convolution. It is constructed using the `build_norm_layer` function with parameters derived from `out_chans // 2` (the number of channels output by the first convolution), `norm_layer`, and input and output formats specified as 'channels_first'.\n",
    "3. `self.act`: The activation layer specified by `act_layer`. It is constructed using the `build_act_layer` function.\n",
    "4. `self.conv2`: Another 2D convolutional layer with parameters similar to `self.conv1`, but now operating on the output channels from the first convolutional layer.\n",
    "5. `self.norm2`: The normalization layer applied after the second convolution. It is constructed using the `build_norm_layer` function with parameters derived from `out_chans` (the total number of output channels), `norm_layer`, and input and output formats specified as 'channels_first' and 'channels_last', respectively.\n",
    "\n",
    "The `forward` method defines the forward pass of the stem layer. It applies each layer sequentially:\n",
    "- Convolution 1\n",
    "- Normalization 1\n",
    "- Activation\n",
    "- Convolution 2\n",
    "- Normalization 2\n",
    "\n",
    "Finally, it returns the output tensor `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemLayer(nn.Module):\n",
    "    r\"\"\" Stem layer of InternImage\n",
    "    Args:\n",
    "        in_chans (int): number of input channels\n",
    "        out_chans (int): number of output channels\n",
    "        act_layer (str): activation layer\n",
    "        norm_layer (str): normalization layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_chans=3,\n",
    "                 out_chans=96,\n",
    "                 act_layer='GELU',\n",
    "                 norm_layer='BN'):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chans,\n",
    "                               out_chans // 2,\n",
    "                               kernel_size=3,\n",
    "                               stride=2,\n",
    "                               padding=1)\n",
    "        self.norm1 = build_norm_layer(out_chans // 2, norm_layer,\n",
    "                                      'channels_first', 'channels_first')\n",
    "        self.act = build_act_layer(act_layer)\n",
    "        self.conv2 = nn.Conv2d(out_chans // 2,\n",
    "                               out_chans,\n",
    "                               kernel_size=3,\n",
    "                               stride=2,\n",
    "                               padding=1)\n",
    "        self.norm2 = build_norm_layer(out_chans, norm_layer, 'channels_first',\n",
    "                                      'channels_last')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class, `DownsampleLayer`, is used to reduce the spatial dimensions of the feature maps in the InternImage network, facilitating hierarchical feature extraction and increasing computational efficiency. \n",
    "\n",
    "The class constructor `__init__` takes the following arguments:\n",
    "- `channels`: The number of input channels to the downsample layer.\n",
    "- `norm_layer`: The type of normalization layer to be used within the downsample layer. Default is 'LN' (Layer Normalization).\n",
    "\n",
    "Inside the constructor, the downsample layer is defined as follows:\n",
    "\n",
    "1. `self.conv`: A 2D convolutional layer (`nn.Conv2d`) with parameters specified by `channels`, `2 * channels` (twice the number of input channels), kernel size 3x3, stride 2, padding 1, and no bias. This layer reduces the spatial dimensions of the input tensor by a factor of 2 while increasing its depth.\n",
    "2. `self.norm`: The normalization layer applied after the convolution. It is constructed using the `build_norm_layer` function with parameters derived from `2 * channels` (the number of output channels from the convolution), `norm_layer`, and input and output formats specified as 'channels_first' and 'channels_last', respectively.\n",
    "\n",
    "The `forward` method defines the forward pass of the downsample layer. It applies each layer sequentially:\n",
    "- Permute the dimensions of the input tensor to convert it from 'channels_last' format to 'channels_first' format.\n",
    "- Convolution\n",
    "- Normalization\n",
    "\n",
    "Finally, it returns the output tensor `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleLayer(nn.Module):\n",
    "    r\"\"\" Downsample layer of InternImage\n",
    "    Args:\n",
    "        channels (int): number of input channels\n",
    "        norm_layer (str): normalization layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, norm_layer='LN'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channels,\n",
    "                              2 * channels,\n",
    "                              kernel_size=3,\n",
    "                              stride=2,\n",
    "                              padding=1,\n",
    "                              bias=False)\n",
    "        self.norm = build_norm_layer(2 * channels, norm_layer,\n",
    "                                     'channels_first', 'channels_last')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x.permute(0, 3, 1, 2))\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class, `MLPLayer`, represents a Multilayer Perceptron (MLP)/Feed-Forward Network (FFN) layer used in the InternImage model. \n",
    "\n",
    "The class constructor `__init__` takes the following arguments:\n",
    "- `in_features`: The number of input features to the MLP layer.\n",
    "- `hidden_features`: The number of hidden features in the MLP layer. If not provided, defaults to `in_features`.\n",
    "- `out_features`: The number of output features from the MLP layer. If not provided, defaults to `in_features`.\n",
    "- `act_layer`: The type of activation layer to be used within the MLP layer. Default is 'GELU' (Gaussian Error Linear Unit).\n",
    "- `drop`: The dropout rate to be applied to the output of the MLP layer. Default is 0.0, meaning no dropout is applied.\n",
    "\n",
    "Inside the constructor, the MLP layer is defined as follows:\n",
    "\n",
    "1. `self.fc1`: A fully connected (linear) layer (`nn.Linear`) mapping the input features to the hidden features.\n",
    "2. `self.act`: The activation layer specified by `act_layer`. It is constructed using the `build_act_layer` function.\n",
    "3. `self.fc2`: Another fully connected layer mapping the hidden features to the output features.\n",
    "4. `self.drop`: A dropout layer (`nn.Dropout`) applied to the output of both fully connected layers, with dropout rate specified by `drop`.\n",
    "\n",
    "The `forward` method defines the forward pass of the MLP layer. It applies each layer sequentially:\n",
    "- Fully connected layer 1 (`self.fc1`)\n",
    "- Activation layer (`self.act`)\n",
    "- Dropout (`self.drop`)\n",
    "- Fully connected layer 2 (`self.fc2`)\n",
    "- Dropout (`self.drop`)\n",
    "\n",
    "Finally, it returns the output tensor `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    r\"\"\" MLP layer of InternImage\n",
    "    Args:\n",
    "        in_features (int): number of input features\n",
    "        hidden_features (int): number of hidden features\n",
    "        out_features (int): number of output features\n",
    "        act_layer (str): activation layer\n",
    "        drop (float): dropout rate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features=None,\n",
    "                 out_features=None,\n",
    "                 act_layer='GELU',\n",
    "                 drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = build_act_layer(act_layer)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=64,\n",
    "depths=[4, 4, 18, 4],\n",
    "groups=[4, 8, 16, 32],\n",
    "mlp_ratio=4.,\n",
    "drop_rate=0.,\n",
    "drop_path_rate=0.2,\n",
    "drop_path_type='linear',\n",
    "act_layer='GELU',\n",
    "norm_layer='LN',\n",
    "layer_scale=None,\n",
    "offset_scale=1.0,\n",
    "post_norm=False,\n",
    "with_cp=False,\n",
    "dw_kernel_size=None,  # for InternImage-H/G\n",
    "level2_post_norm=False,  # for InternImage-H/G\n",
    "level2_post_norm_block_ids=None,  # for InternImage-H/G\n",
    "res_post_norm=False,  # for InternImage-H/G\n",
    "center_feature_scale=False,  # for InternImage-H/G\n",
    "out_indices=(0, 1, 2, 3),\n",
    "init_cfg=None,\n",
    "**kwargs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class, `InternImageLayer`, is a fundamental building block of the InternImage model, incorporating various operations and techniques to enhance feature extraction and modeling capabilities. \n",
    "\n",
    "The class constructor `__init__` takes the following arguments:\n",
    "- `core_op`: The core operation of the InternImage layer, `DCNv3_pytorch`.\n",
    "- `channels`: The number of input channels to the layer.\n",
    "- `groups`: Groups of each block.\n",
    "- `mlp_ratio`: The ratio of MLP hidden features to input channels. Default is 4.0.\n",
    "- `drop`: The dropout rate to be applied within the layer. Default is 0.0.\n",
    "- `drop_path`: The drop path rate. Default is 0.0.\n",
    "- `act_layer`: The type of activation layer to be used within the layer. Default is 'GELU' (Gaussian Error Linear Unit).\n",
    "- `norm_layer`: The type of normalization layer to be used within the layer. Default is 'LN' (Layer Normalization).\n",
    "- `post_norm`: Whether to use post normalization. Default is False.\n",
    "- `layer_scale`: Whether to apply layer scale. Default is None.\n",
    "- `offset_scale`: The offset scale. Default is 1.0.\n",
    "- `with_cp`: Whether to use checkpoint. Default is False.\n",
    "- `dw_kernel_size`: For InternImage-H/G. Default is None.\n",
    "- `res_post_norm`: For InternImage-H/G. Default is False.\n",
    "- `center_feature_scale`: For InternImage-H/G. Default is False.\n",
    "\n",
    "Inside the constructor, the InternImage layer is defined as follows:\n",
    "\n",
    "1. `self.norm1`: The normalization layer applied before the core operation.\n",
    "2. `self.post_norm`: A boolean indicating whether post normalization is used.\n",
    "3. `self.dcn`: The core operation, `DCNv3_pytorch`.\n",
    "4. `self.drop_path`: The drop path layer.\n",
    "5. `self.norm2`: The normalization layer applied after the core operation.\n",
    "6. `self.mlp`: An MLP layer applied after the core operation.\n",
    "7. `self.layer_scale`: A boolean indicating whether layer scale is applied.\n",
    "8. `self.gamma1`, `self.gamma2`: Parameters for layer scaling.\n",
    "9. `self.res_post_norm`: A boolean indicating whether residual post normalization is used.\n",
    "\n",
    "The `forward` method defines the forward pass of the InternImage layer. It applies the core operation, normalization layers, drop path, and optionally layer scale and checkpointing.\n",
    "\n",
    "Within the loop, the input tensor `x` is processed through an inner forward function `_inner_forward(x)`. This function represents the core computational logic of the layer. \n",
    "\n",
    "If `self.layer_scale` is not enabled, indicating that layer scaling is not applied, the forward pass proceeds with the following steps:\n",
    "1. Optionally, post-normalization is applied to the input tensor using `self.norm1`, followed by the core operation `self.dcn`. If post-normalization is not used, the core operation is applied directly to the normalized input tensor. \n",
    "2. The output of the core operation is passed through the `self.drop_path` layer to apply drop path regularization.\n",
    "3. Optionally, post-normalization is applied to the output of the core operation using `self.norm2`, followed by the MLP operation `self.mlp`. If post-normalization is not used, the MLP operation is applied directly to the normalized output of the core operation. \n",
    "4. The output of the MLP operation is again passed through the `self.drop_path` layer to apply drop path regularization.\n",
    "\n",
    "If `self.layer_scale` is enabled, indicating that layer scaling is applied, an additional step is performed:\n",
    "1. The output of the core operation is scaled by learnable parameters `self.gamma1` before post-normalization or the MLP operation. Similarly, the output of the MLP operation is scaled by learnable parameters `self.gamma2`. \n",
    "\n",
    "If `self.with_cp` is enabled and the input tensor `x` requires gradient computation, the forward pass is wrapped in a checkpointing function using `checkpoint.checkpoint(_inner_forward, x)`. This allows for memory optimization during backpropagation by saving intermediate activations. \n",
    "\n",
    "Finally, the processed tensor `x` is returned as the output of the forward pass through the layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b85033b28e07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mInternImageLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     r\"\"\" Basic layer of InternImage\n\u001b[0;32m      3\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcore_op\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcore\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mInternImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class InternImageLayer(nn.Module):\n",
    "    r\"\"\" Basic layer of InternImage\n",
    "    Args:\n",
    "        core_op (nn.Module): core operation of InternImage\n",
    "        channels (int): number of input channels\n",
    "        groups (list): Groups of each block.\n",
    "        mlp_ratio (float): ratio of mlp hidden features to input channels\n",
    "        drop (float): dropout rate\n",
    "        drop_path (float): drop path rate\n",
    "        act_layer (str): activation layer\n",
    "        norm_layer (str): normalization layer\n",
    "        post_norm (bool): whether to use post normalization\n",
    "        layer_scale (float): layer scale\n",
    "        offset_scale (float): offset scale\n",
    "        with_cp (bool): whether to use checkpoint\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 core_op,\n",
    "                 channels,\n",
    "                 groups,\n",
    "                 mlp_ratio=4.,\n",
    "                 drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer='GELU',\n",
    "                 norm_layer='LN',\n",
    "                 post_norm=False,\n",
    "                 layer_scale=None,\n",
    "                 offset_scale=1.0,\n",
    "                 with_cp=False,\n",
    "                 dw_kernel_size=None, # for InternImage-H/G\n",
    "                 res_post_norm=False, # for InternImage-H/G\n",
    "                 center_feature_scale=False): # for InternImage-H/G\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.groups = groups\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.with_cp = with_cp\n",
    "\n",
    "        self.norm1 = build_norm_layer(channels, 'LN')\n",
    "        self.post_norm = post_norm\n",
    "        self.dcn = DCNv3_pytorch(\n",
    "            channels=channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            pad=1,\n",
    "            dilation=1,\n",
    "            group=groups,\n",
    "            offset_scale=offset_scale,\n",
    "            act_layer=act_layer,\n",
    "            norm_layer=norm_layer,\n",
    "            dw_kernel_size=dw_kernel_size, # for InternImage-H/G\n",
    "            center_feature_scale=center_feature_scale) # for InternImage-H/G\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. \\\n",
    "            else nn.Identity()\n",
    "        self.norm2 = build_norm_layer(channels, 'LN')\n",
    "        self.mlp = MLPLayer(in_features=channels,\n",
    "                            hidden_features=int(channels * mlp_ratio),\n",
    "                            act_layer=act_layer,\n",
    "                            drop=drop)\n",
    "        self.layer_scale = layer_scale is not None\n",
    "        if self.layer_scale:\n",
    "            self.gamma1 = nn.Parameter(layer_scale * torch.ones(channels),\n",
    "                                       requires_grad=True)\n",
    "            self.gamma2 = nn.Parameter(layer_scale * torch.ones(channels),\n",
    "                                       requires_grad=True)\n",
    "        self.res_post_norm = res_post_norm\n",
    "        if res_post_norm:\n",
    "            self.res_post_norm1 = build_norm_layer(channels, 'LN')\n",
    "            self.res_post_norm2 = build_norm_layer(channels, 'LN')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            if not self.layer_scale:\n",
    "                if self.post_norm:\n",
    "                    x = x + self.drop_path(self.norm1(self.dcn(x)))\n",
    "                    x = x + self.drop_path(self.norm2(self.mlp(x)))\n",
    "                elif self.res_post_norm: # for InternImage-H/G\n",
    "                    x = x + self.drop_path(self.res_post_norm1(self.dcn(self.norm1(x))))\n",
    "                    x = x + self.drop_path(self.res_post_norm2(self.mlp(self.norm2(x))))\n",
    "                else:\n",
    "                    x = x + self.drop_path(self.dcn(self.norm1(x)))\n",
    "                    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "                return x\n",
    "            if self.post_norm:\n",
    "                x = x + self.drop_path(self.gamma1 * self.norm1(self.dcn(x)))\n",
    "                x = x + self.drop_path(self.gamma2 * self.norm2(self.mlp(x)))\n",
    "            else:\n",
    "                x = x + self.drop_path(self.gamma1 * self.dcn(self.norm1(x)))\n",
    "                x = x + self.drop_path(self.gamma2 * self.mlp(self.norm2(x)))\n",
    "            return x\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            x = checkpoint.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            x = _inner_forward(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `InternImageBlock` class represents the basic block of the InternImage model. It is designed to process input tensors, from the Stem block, through a sequence of InternImageLayer instances. Each of these InternImageLayer instances, has customizable parameters necessary to extract hierarchical features from the input data.\n",
    "\n",
    "The class constructor `__init__` takes several previously discussed arguments as well as the following:\n",
    "- `depth`: The number of InternImage layers (deformable convolution, followed by LN, FFN and LN) to arange sequentially.\n",
    "- `downsample`: Whether to apply downsampling. Default is True.\n",
    "\n",
    "The `forward` method of the `InternImageBlock` iterates over each block in the sequence, applying the forward pass of each corresponding `InternImageLayer` instance to the input tensor `x`, and optionally post normalization is applied if enabled and the block index is in the list of `post_norm_block_ids`. After processing through all the blocks, if post normalization or center feature scale is enabled, the output tensor `x` is normalized using the `norm` layer. If downsampling is enabled, the output tensor `x` is passed through the `DownsampleLayer` instance `downsample` to reduce its spatial dimensions. If the `return_wo_downsample` flag is set to True, the original output tensor `x` before downsampling is saved as `x_`. Finally, the function returns either the downsampled output tensor `x` or both the downsampled output tensor `x` and the original output tensor `x_` depending on the value of `return_wo_downsample`.\n",
    "\n",
    "Let's break down the `InternImageBlock` class forward method:\n",
    "\n",
    "The forward loop in the `InternImageBlock` class iterates over the blocks of `InternImageLayer` instances contained within the `blocks` module list. Each block is applied sequentially to the input tensor `x`.\n",
    "\n",
    "Within the loop:\n",
    "1. For each block, the input tensor `x` is passed through the `InternImageLayer` instance `blk`. This involves applying the core operation, normalization layers, and optionally drop path regularization within the block.\n",
    "2. If post-normalization is enabled and the current block index `i` is in the list of `post_norm_block_ids`, post-normalization is applied to the output tensor `x` using the corresponding post-normalization layer from the `post_norms` module list.\n",
    "3. If post-normalization is not enabled or if `center_feature_scale` is True, the output tensor `x` is normalized using the `norm` layer.\n",
    "4. If downsampling is enabled (`downsample` is not None), the output tensor `x` is passed through the `DownsampleLayer` instance `downsample` to reduce its spatial dimensions.\n",
    "5. If `return_wo_downsample` is True, the original output tensor `x` before downsampling is saved as `x_`.\n",
    "\n",
    "Finally, the function returns either the downsampled output tensor `x` or both the downsampled output tensor `x` and the original output tensor `x_`, depending on the value of `return_wo_downsample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternImageBlock(nn.Module):\n",
    "    r\"\"\" Block of InternImage\n",
    "    Args:\n",
    "        core_op (nn.Module): core operation of InternImage\n",
    "        channels (int): number of input channels\n",
    "        depths (list): Depth of each block.\n",
    "        groups (list): Groups of each block.\n",
    "        mlp_ratio (float): ratio of mlp hidden features to input channels\n",
    "        drop (float): dropout rate\n",
    "        drop_path (float): drop path rate\n",
    "        act_layer (str): activation layer\n",
    "        norm_layer (str): normalization layer\n",
    "        post_norm (bool): whether to use post normalization\n",
    "        layer_scale (float): layer scale\n",
    "        offset_scale (float): offset scale\n",
    "        with_cp (bool): whether to use checkpoint\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 core_op,\n",
    "                 channels,\n",
    "                 depth,\n",
    "                 groups,\n",
    "                 downsample=True,\n",
    "                 mlp_ratio=4.,\n",
    "                 drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer='GELU',\n",
    "                 norm_layer='LN',\n",
    "                 post_norm=False,\n",
    "                 offset_scale=1.0,\n",
    "                 layer_scale=None,\n",
    "                 with_cp=False,\n",
    "                 dw_kernel_size=None, # for InternImage-H/G\n",
    "                 post_norm_block_ids=None, # for InternImage-H/G\n",
    "                 res_post_norm=False, # for InternImage-H/G\n",
    "                 center_feature_scale=False): # for InternImage-H/G\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.depth = depth\n",
    "        self.post_norm = post_norm\n",
    "        self.center_feature_scale = center_feature_scale\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            InternImageLayer(\n",
    "                core_op=core_op,\n",
    "                channels=channels,\n",
    "                groups=groups,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                drop=drop,\n",
    "                drop_path=drop_path[i] if isinstance(\n",
    "                    drop_path, list) else drop_path,\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                post_norm=post_norm,\n",
    "                layer_scale=layer_scale,\n",
    "                offset_scale=offset_scale,\n",
    "                with_cp=with_cp,\n",
    "                dw_kernel_size=dw_kernel_size, # for InternImage-H/G\n",
    "                res_post_norm=res_post_norm, # for InternImage-H/G\n",
    "                center_feature_scale=center_feature_scale # for InternImage-H/G\n",
    "            ) for i in range(depth)\n",
    "        ])\n",
    "        if not self.post_norm or center_feature_scale:\n",
    "            self.norm = build_norm_layer(channels, 'LN')\n",
    "        self.post_norm_block_ids = post_norm_block_ids\n",
    "        if post_norm_block_ids is not None: # for InternImage-H/G\n",
    "            self.post_norms = nn.ModuleList(\n",
    "                [build_norm_layer(channels, 'LN', eps=1e-6) for _ in post_norm_block_ids]\n",
    "            )\n",
    "        self.downsample = DownsampleLayer(\n",
    "            channels=channels, norm_layer=norm_layer) if downsample else None\n",
    "\n",
    "    def forward(self, x, return_wo_downsample=False):\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            x = blk(x)\n",
    "            if (self.post_norm_block_ids is not None) and (i in self.post_norm_block_ids):\n",
    "                index = self.post_norm_block_ids.index(i)\n",
    "                x = self.post_norms[index](x) # for InternImage-H/G\n",
    "        if not self.post_norm or self.center_feature_scale:\n",
    "            x = self.norm(x)\n",
    "        if return_wo_downsample:\n",
    "            x_ = x\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        if return_wo_downsample:\n",
    "            return x, x_\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `InternImage` class is an implementation of the InternImage model. This class represents the InternImage Encoder. It returns a list of tensors, each corresponding to a corresponding stage.\n",
    "\n",
    "The model architecture consists of a series of stages, each containing multiple levels represented by `InternImageBlock` instances. These blocks are designed to process input tensors through a combination of deformable convolutions, normalization, activation, and downsampling operations. The model utilizes the specified core operator, activation layer, normalization layer, and dropout settings to learn hierarchical representations from the input data.\n",
    "\n",
    "The class constructor `__init__` takes several arguments:\n",
    "- `core_op` (str): Specifies the core operator for the model. Default: 'DCNv3_pytorch'.\n",
    "- `channels` (int): Number of channels in the first stage of the model. Default: 64.\n",
    "- `depths` (list): Depth of each block within the model. Default: [4, 4, 18, 4].\n",
    "- `groups` (list): Number of groups for each block. Default: [4, 8, 16, 32].\n",
    "- `mlp_ratio` (float): Ratio of MLP hidden dimension to embedding dimension. Default: 4.0.\n",
    "- `drop_rate` (float): Dropout probability. Default: 0.0.\n",
    "- `drop_path_rate` (float): Stochastic depth rate. Default: 0.2.\n",
    "- `drop_path_type` (str): Type of drop path strategy ('linear' or 'uniform'). Default: 'linear'.\n",
    "- `act_layer` (str): Activation layer. Default: 'GELU'.\n",
    "- `norm_layer` (str): Normalization layer. Default: 'LN'.\n",
    "- `layer_scale` (bool): Whether to use layer scale. Default: None.\n",
    "- `offset_scale` (float): Scale factor for offsets in deformable convolutions. Default: 1.0.\n",
    "- `post_norm` (bool): Whether to use post normalization. Default: False.\n",
    "- `with_cp` (bool): Whether to use checkpointing during training. Default: False.\n",
    "- `dw_kernel_size` (int): Size of the depthwise convolution kernel. Default: None.\n",
    "- `level2_post_norm` (bool): Whether to use level 2 post normalization. Default: False.\n",
    "- `level2_post_norm_block_ids` (list): Indexes of post normalization blocks for level 2. Default: None.\n",
    "- `res_post_norm` (bool): Whether to use residual post normalization. Default: False.\n",
    "- `center_feature_scale` (bool): Whether to use center feature scale. Default: False.\n",
    "- `out_indices` (tuple): Indexes of levels to output features from. Default: (0, 1, 2, 3).\n",
    "- `init_cfg` (dict): Configuration for weight initialization. Default: None.\n",
    "- Additional keyword arguments (`**kwargs`) for flexibility and extensibility.\n",
    "\n",
    "The forward pass in the `InternImage` class involves embedding the input image patches, applying positional dropout, processing the embedded features through each level of the model, collecting features from specified levels, and returning the collected features for further analysis or downstream tasks. Let's outline the steps for the forward pass more clearly: \n",
    "\n",
    "1. **Patch Embedding:** \n",
    "   - The input image tensor `x` is passed through the `patch_embed` module, which performs patch embedding to extract features from the image. \n",
    "   - The output is a tensor representing the embedded patches.\n",
    "\n",
    "2. **Positional Dropout:**\n",
    "   - The embedded patches undergo positional dropout, which randomly zeroes out elements in the tensor based on a dropout probability specified by `drop_rate`.\n",
    "   - This helps regularize the model and prevent overfitting by adding noise to the embedded features.\n",
    "\n",
    "3. **Processing through Levels:**\n",
    "   - The embedded and dropout-applied tensor is sequentially processed through each level of the model.\n",
    "   - For each level, the tensor is passed through an `InternImageBlock` instance, which applies a series of operations including deformable convolutions, normalization, activation, and optionally downsampling.\n",
    "   - The output of each level is collected and stored for further processing.\n",
    "\n",
    "4. **Output Collection:**\n",
    "   - Features from specified levels, as indicated by `out_indices`, are collected and stored in `seq_out`.\n",
    "   - These features represent hierarchical representations of the input image at different scales, capturing both low-level and high-level information.\n",
    "\n",
    "5. **Return:**\n",
    "   - The collected features (`seq_out`) are returned as the output of the forward pass.\n",
    "   - These features can be used for downstream tasks such as classification, object detection, or segmentation.\n",
    "\n",
    "\n",
    "Overall, the `InternImage` class encapsulates the architecture and functionality of the InternImage model, providing a versatile and scalable solution for various computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternImage(nn.Module):\n",
    "    r\"\"\" InternImage\n",
    "        A PyTorch impl of : `InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions`  -\n",
    "          https://arxiv.org/pdf/2103.14030\n",
    "    Args:\n",
    "        core_op (str): Core operator. Default: 'DCNv3'\n",
    "        channels (int): Number of the first stage. Default: 64\n",
    "        depths (list): Depth of each block. Default: [4, 4, 18, 4]\n",
    "        groups (list): Groups of each block. Default: [4, 8, 16, 32]\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4.\n",
    "        drop_rate (float): Probability of an element to be zeroed. Default: 0.\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        act_layer (str): Activation layer. Default: 'GELU'\n",
    "        norm_layer (str): Normalization layer. Default: 'LN'\n",
    "        layer_scale (bool): Whether to use layer scale. Default: False\n",
    "        cls_scale (bool): Whether to use class scale. Default: False\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "        dw_kernel_size (int): Size of the dwconv. Default: None\n",
    "        level2_post_norm (bool): Whether to use level2 post norm. Default: False\n",
    "        level2_post_norm_block_ids (list): Indexes of post norm blocks. Default: None\n",
    "        res_post_norm (bool): Whether to use res post norm. Default: False\n",
    "        center_feature_scale (bool): Whether to use center feature scale. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 core_op='DCNv3_pytorch',\n",
    "                 channels=64,\n",
    "                 depths=[4, 4, 18, 4],\n",
    "                groups=[4, 8, 16, 32],\n",
    "                 mlp_ratio=4.,\n",
    "                 drop_rate=0.,\n",
    "                 drop_path_rate=0.2,\n",
    "                 drop_path_type='linear',\n",
    "                 act_layer='GELU',\n",
    "                 norm_layer='LN',\n",
    "                 layer_scale=None,\n",
    "                 offset_scale=1.0,\n",
    "                 post_norm=False,\n",
    "                 with_cp=False,\n",
    "                 dw_kernel_size=None,  # for InternImage-H/G\n",
    "                 level2_post_norm=False,  # for InternImage-H/G\n",
    "                 level2_post_norm_block_ids=None,  # for InternImage-H/G\n",
    "                 res_post_norm=False,  # for InternImage-H/G\n",
    "                 center_feature_scale=False,  # for InternImage-H/G\n",
    "                 out_indices=(0, 1, 2, 3),\n",
    "                 init_cfg=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.core_op = core_op\n",
    "        self.num_levels = len(depths)\n",
    "        self.depths = depths\n",
    "        self.channels = channels\n",
    "        self.num_features = int(channels * 2**(self.num_levels - 1))\n",
    "        self.post_norm = post_norm\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.init_cfg = init_cfg\n",
    "        self.out_indices = out_indices\n",
    "        self.level2_post_norm_block_ids = level2_post_norm_block_ids\n",
    "        logger = get_root_logger()\n",
    "        logger.info(f'using core type: {core_op}')\n",
    "        logger.info(f'using activation layer: {act_layer}')\n",
    "        logger.info(f'using main norm layer: {norm_layer}')\n",
    "        logger.info(f'using dpr: {drop_path_type}, {drop_path_rate}')\n",
    "        logger.info(f\"level2_post_norm: {level2_post_norm}\")\n",
    "        logger.info(f\"level2_post_norm_block_ids: {level2_post_norm_block_ids}\")\n",
    "        logger.info(f\"res_post_norm: {res_post_norm}\")\n",
    "\n",
    "        in_chans = 3\n",
    "        self.patch_embed = StemLayer(in_chans=in_chans,\n",
    "                                     out_chans=channels,\n",
    "                                     act_layer=act_layer,\n",
    "                                     norm_layer=norm_layer)\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = [\n",
    "            x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))\n",
    "        ]\n",
    "        if drop_path_type == 'uniform':\n",
    "            for i in range(len(dpr)):\n",
    "                dpr[i] = drop_path_rate\n",
    "\n",
    "        self.levels = nn.ModuleList()\n",
    "        for i in range(self.num_levels):\n",
    "            post_norm_block_ids = level2_post_norm_block_ids if level2_post_norm and (\n",
    "                i == 2) else None # for InternImage-H/G\n",
    "            level = InternImageBlock(\n",
    "                core_op=core_op,\n",
    "                channels=int(channels * 2**i),\n",
    "                depth=depths[i],\n",
    "                groups=groups[i],\n",
    "                mlp_ratio=self.mlp_ratio,\n",
    "                drop=drop_rate,\n",
    "                drop_path=dpr[sum(depths[:i]):sum(depths[:i + 1])],\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                post_norm=post_norm,\n",
    "                downsample=(i < self.num_levels - 1),\n",
    "                layer_scale=layer_scale,\n",
    "                offset_scale=offset_scale,\n",
    "                with_cp=with_cp,\n",
    "                dw_kernel_size=dw_kernel_size,  # for InternImage-H/G\n",
    "                post_norm_block_ids=post_norm_block_ids, # for InternImage-H/G\n",
    "                res_post_norm=res_post_norm, # for InternImage-H/G\n",
    "                center_feature_scale=center_feature_scale # for InternImage-H/G\n",
    "            )\n",
    "            self.levels.append(level)\n",
    "\n",
    "        self.num_layers = len(depths)\n",
    "        self.apply(self._init_weights)\n",
    "        self.apply(self._init_deform_weights)\n",
    "\n",
    "    def init_weights(self):\n",
    "        logger = get_root_logger()\n",
    "        if self.init_cfg is None:\n",
    "            logger.warn(f'No pre-trained weights for '\n",
    "                        f'{self.__class__.__name__}, '\n",
    "                        f'training start from scratch')\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    trunc_normal_init(m, std=.02, bias=0.)\n",
    "                elif isinstance(m, nn.LayerNorm):\n",
    "                    constant_init(m, 1.0)\n",
    "        else:\n",
    "            assert 'checkpoint' in self.init_cfg, f'Only support ' \\\n",
    "                                                  f'specify `Pretrained` in ' \\\n",
    "                                                  f'`init_cfg` in ' \\\n",
    "                                                  f'{self.__class__.__name__} '\n",
    "            ckpt = _load_checkpoint(self.init_cfg.checkpoint,\n",
    "                                    logger=logger,\n",
    "                                    map_location='cpu')\n",
    "            if 'state_dict' in ckpt:\n",
    "                _state_dict = ckpt['state_dict']\n",
    "            elif 'model' in ckpt:\n",
    "                _state_dict = ckpt['model']\n",
    "            else:\n",
    "                _state_dict = ckpt\n",
    "\n",
    "            state_dict = OrderedDict()\n",
    "            for k, v in _state_dict.items():\n",
    "                if k.startswith('backbone.'):\n",
    "                    state_dict[k[9:]] = v\n",
    "                else:\n",
    "                    state_dict[k] = v\n",
    "\n",
    "            # strip prefix of state_dict\n",
    "            if list(state_dict.keys())[0].startswith('module.'):\n",
    "                state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "\n",
    "            # load state_dict\n",
    "            meg = self.load_state_dict(state_dict, False)\n",
    "            logger.info(meg)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def _init_deform_weights(self, m):\n",
    "        import sys\n",
    "        import os\n",
    "\n",
    "        # Assuming your 'modules' directory is one level up from internimage.py\n",
    "        sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "        # Now you can import dcnv3_pytorch as opsm\n",
    "        import modules.dcnv3_pytorch as opsm\n",
    "        if isinstance(m, getattr(opsm, self.core_op)):\n",
    "            m._reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        seq_out = []\n",
    "        for level_idx, level in enumerate(self.levels):\n",
    "            x, x_ = level(x, return_wo_downsample=True)\n",
    "            if level_idx in self.out_indices:\n",
    "                seq_out.append(x_.permute(0, 3, 1, 2).contiguous())\n",
    "        return seq_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using these modules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intern Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input tensor shape\n",
    "batch_size = 5\n",
    "channels = 3\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(batch_size, channels, height, width)\n",
    "\n",
    "# Initialize the Encoder/backbone of our model\n",
    "backbone = InternImage(\n",
    "            channels = 64,\n",
    "            depths=[4, 4, 18, 4], \n",
    "            groups=[4, 8, 16, 32],\n",
    "            mlp_ratio = 4.,\n",
    "            drop_path_rate = 0.2,\n",
    "            norm_layer='LN',\n",
    "            offset_scale=1.0,\n",
    "            post_norm=False,\n",
    "            with_cp=False, \n",
    "            out_indices=(0, 1, 2, 3),\n",
    "            feature_channels=[64, 128, 256, 512])\n",
    "\n",
    "# Forward pass through the model\n",
    "output = backbone(input_tensor)\n",
    "\n",
    "# Print the shapes of input and output\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Print the shapes of output features from each level\n",
    "for i, features in enumerate(output):\n",
    "    print(f\"Level {i}: {features.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
